# ALOHA æ•°æ®è½¬æ¢å’Œ SmolVLA è®­ç»ƒæŒ‡å—

æœ¬æŒ‡å—æä¾›è¯¦ç»†çš„æ­¥éª¤æ¥è½¬æ¢ALOHA HDF5æ•°æ®é›†åˆ°LeRobot v3.0æ ¼å¼ï¼Œå¹¶ä½¿ç”¨è¯¥æ•°æ®é›†è®­ç»ƒSmolVLAæ¨¡å‹ã€‚

## ç›®å½•

- [ç¯å¢ƒè®¾ç½®](#ç¯å¢ƒè®¾ç½®)
- [æ•°æ®è½¬æ¢](#æ•°æ®è½¬æ¢)
- [è®­ç»ƒSmolVLA](#è®­ç»ƒsmolvla)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ç¯å¢ƒè®¾ç½®

### 1. åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

```bash
conda create -y -n lerobot python=3.10
conda activate lerobot
```

### 2. å®‰è£…FFmpeg

```bash
conda install ffmpeg -c conda-forge
```

### 3. å®‰è£…LeRobot

ä»æºç å®‰è£…ï¼ˆæ¨èç”¨äºå¼€å‘ï¼‰ï¼š

```bash
git clone https://github.com/huggingface/lerobot.git
cd lerobot
pip install -e .
```

### 4. å®‰è£…SmolVLAä¾èµ–

```bash
pip install -e ".[smolvla]"
```

è¿™ä¼šå®‰è£…ä»¥ä¸‹ä¾èµ–ï¼š
- transformers>=4.53.0
- num2words
- accelerate>=1.7.0
- safetensors>=0.4.3

### 5. é…ç½®Weights & Biasesï¼ˆå¯é€‰ï¼‰

å¦‚æœä½ æƒ³ä½¿ç”¨W&Bè¿›è¡Œå®éªŒè·Ÿè¸ªï¼š

```bash
wandb login
```

---

## æ•°æ®è½¬æ¢

### æ•°æ®å‡†å¤‡

åœ¨è½¬æ¢ä¹‹å‰ï¼Œä½ éœ€è¦å‡†å¤‡ï¼š

1. **HDF5æ–‡ä»¶ç›®å½•**ï¼šåŒ…å«ALOHAå½•åˆ¶çš„episodeæ–‡ä»¶ï¼ˆ`episode0.hdf5`, `episode1.hdf5`ç­‰ï¼‰
2. **æŒ‡ä»¤æ–‡ä»¶ç›®å½•**ï¼šåŒ…å«æ¯ä¸ªepisodeçš„æŒ‡ä»¤JSONæ–‡ä»¶

#### æŒ‡ä»¤æ–‡ä»¶æ ¼å¼

ä¸ºæ¯ä¸ªepisodeåˆ›å»ºä¸€ä¸ªJSONæ–‡ä»¶ï¼ˆä¾‹å¦‚`episode0.json`, `episode1.json`ï¼‰ï¼š

```json
{
  "seen": [
    "pick up the red block",
    "grasp the red object",
    "take the red cube"
  ]
}
```

è„šæœ¬ä¼šä»`seen`åˆ—è¡¨ä¸­éšæœºé€‰æ‹©ä¸€æ¡æŒ‡ä»¤ã€‚

### è½¬æ¢å‘½ä»¤

#### åŸºæœ¬è½¬æ¢

```bash
python examples/port_datasets/port_aloha_hdf5.py \
    --raw-dir /path/to/hdf5/files \
    --instruction-dir /path/to/instructions \
    --repo-id username/my-aloha-dataset \
    --output-dir /path/to/output
```

#### å‚æ•°è¯´æ˜

- `--raw-dir`: HDF5æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆå¿…éœ€ï¼‰
- `--instruction-dir`: æŒ‡ä»¤JSONæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆå¿…éœ€ï¼‰
- `--repo-id`: æ•°æ®é›†æ ‡è¯†ç¬¦ï¼Œæ ¼å¼ï¼š`username/dataset-name`ï¼ˆå¿…éœ€ï¼‰
- `--output-dir`: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼š`~/.cache/huggingface/lerobot/{repo-id}`ï¼‰
- `--episodes`: è¦è½¬æ¢çš„ç‰¹å®šepisodeç´¢å¼•åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼šå…¨éƒ¨ï¼‰
- `--push-to-hub`: æ˜¯å¦ä¸Šä¼ åˆ°Hugging Face Hubï¼ˆå¯é€‰ï¼‰

#### ç¤ºä¾‹

##### è½¬æ¢æ‰€æœ‰episodesåˆ°è‡ªå®šä¹‰ç›®å½•

```bash
python examples/port_datasets/port_aloha_hdf5.py \
    --raw-dir ./data/raw/aloha_recordings \
    --instruction-dir ./data/instructions \
    --repo-id myusername/aloha-pick-place \
    --output-dir ./data/lerobot/aloha-pick-place
```

##### è½¬æ¢ç‰¹å®šepisodes

```bash
python examples/port_datasets/port_aloha_hdf5.py \
    --raw-dir ./data/raw/aloha_recordings \
    --instruction-dir ./data/instructions \
    --repo-id myusername/aloha-pick-place \
    --output-dir ./data/lerobot/aloha-pick-place \
    --episodes 0 1 2 3 4
```

##### è½¬æ¢å¹¶ä¸Šä¼ åˆ°Hub

```bash
python examples/port_datasets/port_aloha_hdf5.py \
    --raw-dir ./data/raw/aloha_recordings \
    --instruction-dir ./data/instructions \
    --repo-id myusername/aloha-pick-place \
    --push-to-hub
```

### éªŒè¯è½¬æ¢åçš„æ•°æ®é›†

#### ä½¿ç”¨å¯è§†åŒ–å·¥å…·

```bash
lerobot-dataset-viz \
    --repo-id myusername/aloha-pick-place \
    --root ./data/lerobot \
    --mode local \
    --episode-index 0
```

è¿™ä¼šæ‰“å¼€Rerun.ioç•Œé¢ï¼Œæ˜¾ç¤ºç›¸æœºæµã€æœºå™¨äººçŠ¶æ€å’ŒåŠ¨ä½œã€‚

#### åŠ è½½æ•°æ®é›†è¿›è¡Œæ£€æŸ¥

```python
from lerobot.datasets.lerobot_dataset import LeRobotDataset

# ä»æœ¬åœ°åŠ è½½
dataset = LeRobotDataset(
    repo_id="myusername/aloha-pick-place",
    root="./data/lerobot"
)

print(f"Total episodes: {dataset.meta.total_episodes}")
print(f"Total frames: {dataset.meta.total_frames}")
print(f"FPS: {dataset.meta.info['fps']}")
print(f"Features: {list(dataset.features.keys())}")

# æŸ¥çœ‹ç¬¬ä¸€å¸§
sample = dataset[0]
for key in sample.keys():
    print(f"{key}: {sample[key].shape if hasattr(sample[key], 'shape') else type(sample[key])}")
```

### è½¬æ¢åçš„æ•°æ®é›†ç»“æ„

```
output_dir/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ chunk-000/
â”‚       â””â”€â”€ file-000.parquet          # çŠ¶æ€å’ŒåŠ¨ä½œæ•°æ®
â”œâ”€â”€ videos/
â”‚   â””â”€â”€ {camera_name}/
â”‚       â””â”€â”€ chunk-000/
â”‚           â””â”€â”€ file-000.mp4          # è§†é¢‘æ•°æ®
â””â”€â”€ meta/
    â”œâ”€â”€ info.json                      # æ•°æ®é›†å…ƒä¿¡æ¯
    â”œâ”€â”€ episodes/                      # Episodeå…ƒæ•°æ®
    â”œâ”€â”€ tasks/                         # ä»»åŠ¡ä¿¡æ¯
    â””â”€â”€ episodes_stats/                # Episodeç»Ÿè®¡ä¿¡æ¯
```

---

## è®­ç»ƒSmolVLA

### æ–¹æ³•1: ä½¿ç”¨å‘½ä»¤è¡Œè®­ç»ƒï¼ˆæ¨èï¼‰

#### åŸºæœ¬è®­ç»ƒå‘½ä»¤

```bash
lerobot-train \
    --policy-name smolvla \
    --repo-id myusername/aloha-pick-place \
    --root ./data/lerobot \
    --output-dir outputs/smolvla_aloha \
    --num-train-iters 10000 \
    --batch-size 8 \
    --eval-freq 1000 \
    --save-freq 1000 \
    --log-freq 100
```

#### å‚æ•°è¯´æ˜

- `--policy-name`: ç­–ç•¥ç±»å‹ï¼ˆè¿™é‡Œä½¿ç”¨`smolvla`ï¼‰
- `--repo-id`: æ•°æ®é›†çš„repo ID
- `--root`: æ•°æ®é›†æœ¬åœ°è·¯å¾„ï¼ˆå¦‚æœä½¿ç”¨æœ¬åœ°æ•°æ®é›†ï¼‰
- `--output-dir`: è®­ç»ƒè¾“å‡ºç›®å½•
- `--num-train-iters`: è®­ç»ƒè¿­ä»£æ¬¡æ•°
- `--batch-size`: æ‰¹é‡å¤§å°
- `--eval-freq`: è¯„ä¼°é¢‘ç‡
- `--save-freq`: ä¿å­˜æ£€æŸ¥ç‚¹é¢‘ç‡
- `--log-freq`: æ—¥å¿—è®°å½•é¢‘ç‡

#### ä½¿ç”¨W&Bè¿›è¡Œå®éªŒè·Ÿè¸ª

```bash
lerobot-train \
    --policy-name smolvla \
    --repo-id myusername/aloha-pick-place \
    --root ./data/lerobot \
    --output-dir outputs/smolvla_aloha \
    --num-train-iters 10000 \
    --batch-size 8 \
    --use-wandb \
    --wandb-project my-robotics-project \
    --wandb-run-name smolvla-aloha-run1
```

#### å¤šGPUè®­ç»ƒ

```bash
accelerate launch --multi_gpu --num_processes=4 \
    src/lerobot/scripts/lerobot_train.py \
    --policy-name smolvla \
    --repo-id myusername/aloha-pick-place \
    --root ./data/lerobot \
    --output-dir outputs/smolvla_aloha \
    --num-train-iters 10000 \
    --batch-size 32
```

### æ–¹æ³•2: ä½¿ç”¨Pythonè„šæœ¬è®­ç»ƒ

åˆ›å»ºè®­ç»ƒè„šæœ¬ `train_smolvla.py`ï¼š

```python
from pathlib import Path
import torch
from lerobot.configs.types import FeatureType
from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata
from lerobot.datasets.utils import dataset_to_policy_features
from lerobot.policies.smolvla.configuration_smolvla import SmolVLAConfig
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
from lerobot.policies.factory import make_pre_post_processors

def main():
    # é…ç½®
    output_directory = Path("outputs/train/smolvla_aloha")
    output_directory.mkdir(parents=True, exist_ok=True)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    training_steps = 10000
    batch_size = 8
    learning_rate = 1e-4
    log_freq = 100

    # åŠ è½½æ•°æ®é›†å…ƒæ•°æ®
    dataset_metadata = LeRobotDatasetMetadata(
        repo_id="myusername/aloha-pick-place",
        root="./data/lerobot"
    )

    # å‡†å¤‡ç‰¹å¾é…ç½®
    features = dataset_to_policy_features(dataset_metadata.features)
    output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}
    input_features = {key: ft for key, ft in features.items() if key not in output_features}

    # åˆ›å»ºç­–ç•¥é…ç½®
    cfg = SmolVLAConfig(
        input_features=input_features,
        output_features=output_features
    )

    # åˆå§‹åŒ–ç­–ç•¥
    policy = SmolVLAPolicy(cfg)
    policy.train()
    policy.to(device)

    # åˆ›å»ºé¢„å¤„ç†å™¨å’Œåå¤„ç†å™¨
    preprocessor, postprocessor = make_pre_post_processors(
        cfg,
        dataset_stats=dataset_metadata.stats
    )

    # å‡†å¤‡delta_timestampsï¼ˆæ ¹æ®ç­–ç•¥è¦æ±‚ï¼‰
    delta_timestamps = {
        f"observation.images.{key}": [i / dataset_metadata.fps for i in cfg.observation_delta_indices]
        for key in dataset_metadata.video_keys
    }
    delta_timestamps.update({
        "observation.state": [i / dataset_metadata.fps for i in cfg.observation_delta_indices],
        "action": [i / dataset_metadata.fps for i in cfg.action_delta_indices],
    })

    # åŠ è½½æ•°æ®é›†
    dataset = LeRobotDataset(
        repo_id="myusername/aloha-pick-place",
        root="./data/lerobot",
        delta_timestamps=delta_timestamps
    )

    # åˆ›å»ºä¼˜åŒ–å™¨å’Œæ•°æ®åŠ è½½å™¨
    optimizer = torch.optim.AdamW(policy.parameters(), lr=learning_rate)
    dataloader = torch.utils.data.DataLoader(
        dataset,
        num_workers=4,
        batch_size=batch_size,
        shuffle=True,
        pin_memory=device.type != "cpu",
        drop_last=True,
    )

    # è®­ç»ƒå¾ªç¯
    step = 0
    done = False
    print(f"Starting training for {training_steps} steps...")

    while not done:
        for batch in dataloader:
            batch = preprocessor(batch)
            loss, _ = policy.forward(batch)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()

            if step % log_freq == 0:
                print(f"Step: {step}/{training_steps}, Loss: {loss.item():.4f}")

            step += 1
            if step >= training_steps:
                done = True
                break

    # ä¿å­˜æ¨¡å‹
    print(f"Saving model to {output_directory}")
    policy.save_pretrained(output_directory)
    preprocessor.save_pretrained(output_directory)
    postprocessor.save_pretrained(output_directory)
    print("Training complete!")

if __name__ == "__main__":
    main()
```

è¿è¡Œè„šæœ¬ï¼š

```bash
python train_smolvla.py
```

### ä»é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ

```bash
lerobot-train \
    --policy-name smolvla \
    --pretrained-model-path lerobot/smolvla_base \
    --repo-id myusername/aloha-pick-place \
    --root ./data/lerobot \
    --output-dir outputs/smolvla_aloha_finetuned \
    --num-train-iters 5000 \
    --batch-size 8
```

### è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹

```bash
lerobot-eval \
    --policy-path outputs/smolvla_aloha \
    --env aloha \
    --num-episodes 10 \
    --output-dir outputs/eval_results
```

### ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†

```python
import torch
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
from lerobot.policies.factory import make_pre_post_processors

# åŠ è½½æ¨¡å‹
model_path = "outputs/smolvla_aloha"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

policy = SmolVLAPolicy.from_pretrained(model_path)
policy.eval()
policy.to(device)

preprocess, postprocess = make_pre_post_processors(
    policy.config,
    model_path,
    preprocessor_overrides={"device_processor": {"device": str(device)}}
)

# æ¨ç†ç¤ºä¾‹ï¼ˆéœ€è¦è¿æ¥çœŸå®æœºå™¨äººæˆ–ä»¿çœŸç¯å¢ƒï¼‰
# observation = get_observation_from_robot()
# obs_frame = build_inference_frame(observation, ...)
# obs = preprocess(obs_frame)
# action = policy.select_action(obs)
# action = postprocess(action)
# send_action_to_robot(action)
```

---

## å¸¸è§é—®é¢˜

### Q1: è½¬æ¢æ—¶å‡ºç°"No module named 'cv2'"é”™è¯¯

**A**: å®‰è£…OpenCVï¼š

```bash
pip install opencv-python-headless
```

æˆ–è€…å®‰è£…å®Œæ•´çš„lerobotä¾èµ–ï¼š

```bash
pip install -e ".[all]"
```

### Q2: å†…å­˜ä¸è¶³é”™è¯¯

**A**: å°è¯•å‡å°æ‰¹é‡å¤§å°ï¼š

```bash
lerobot-train \
    ... \
    --batch-size 4
```

æˆ–è€…ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼š

```bash
lerobot-train \
    ... \
    --batch-size 4 \
    --gradient-accumulation-steps 2
```

### Q3: å¦‚ä½•æŸ¥çœ‹å¯ç”¨çš„æ‘„åƒå¤´ï¼Ÿ

**A**: åœ¨è½¬æ¢åæŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯ï¼š

```python
from lerobot.datasets.lerobot_dataset import LeRobotDatasetMetadata

meta = LeRobotDatasetMetadata(
    repo_id="myusername/aloha-pick-place",
    root="./data/lerobot"
)

print("Available cameras:", meta.video_keys)
```

### Q4: è®­ç»ƒæ—¶GPUåˆ©ç”¨ç‡ä½

**A**:
1. å¢åŠ æ•°æ®åŠ è½½çš„workeræ•°é‡ï¼š`--num-workers 8`
2. ä½¿ç”¨æ›´å¤§çš„æ‰¹é‡å¤§å°
3. å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆå¦‚æœä½¿ç”¨accelerateï¼‰

### Q5: å¦‚ä½•æ¢å¤ä¸­æ–­çš„è®­ç»ƒï¼Ÿ

**A**: ä½¿ç”¨checkpointæ¢å¤ï¼š

```bash
lerobot-train \
    --resume-from outputs/smolvla_aloha/checkpoint-5000 \
    ...å…¶ä»–å‚æ•°...
```

### Q6: æ•°æ®é›†è½¬æ¢éœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

**A**: å–å†³äºï¼š
- Episodeæ•°é‡å’Œé•¿åº¦
- å›¾åƒåˆ†è¾¨ç‡
- ç¡¬ç›˜é€Ÿåº¦

å‚è€ƒï¼š50ä¸ªepisodesï¼ˆæ¯ä¸ª~200å¸§ï¼Œ2ä¸ªæ‘„åƒå¤´640x480ï¼‰å¤§çº¦éœ€è¦5-15åˆ†é’Ÿã€‚

### Q7: è½¬æ¢åçš„æ•°æ®é›†å¤§å°æ˜¯å¤šå°‘ï¼Ÿ

**A**:
- ä½¿ç”¨è§†é¢‘å‹ç¼©ï¼ˆMP4ï¼‰ï¼šçº¦ä¸ºåŸHDF5çš„30-50%
- ä¸ä½¿ç”¨è§†é¢‘ï¼šçº¦ä¸ºåŸHDF5çš„10-20%ï¼ˆä»…parquetï¼‰

### Q8: å¦‚ä½•éªŒè¯æ•°æ®é›†æ ¼å¼æ­£ç¡®ï¼Ÿ

**A**: è¿è¡ŒéªŒè¯ï¼š

```python
from lerobot.datasets.lerobot_dataset import LeRobotDataset

try:
    dataset = LeRobotDataset(
        repo_id="myusername/aloha-pick-place",
        root="./data/lerobot"
    )
    print("âœ“ Dataset loaded successfully!")
    print(f"  Total episodes: {dataset.meta.total_episodes}")
    print(f"  Total frames: {dataset.meta.total_frames}")

    # æµ‹è¯•è¯»å–ä¸€å¸§
    sample = dataset[0]
    print("âœ“ Successfully read first frame!")

except Exception as e:
    print(f"âœ— Error loading dataset: {e}")
```

---

## é¢å¤–èµ„æº

- [LeRobot Documentation](https://huggingface.co/docs/lerobot)
- [LeRobot GitHub](https://github.com/huggingface/lerobot)
- [SmolVLA Model Card](https://huggingface.co/lerobot/smolvla_base)
- [LeRobot Discord](https://discord.gg/s3KuuzsPFb)

---

## å®Œæ•´å·¥ä½œæµç¤ºä¾‹

ä»¥ä¸‹æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç«¯åˆ°ç«¯å·¥ä½œæµï¼š

```bash
# 1. åˆ›å»ºç¯å¢ƒ
conda create -y -n lerobot python=3.10
conda activate lerobot
conda install ffmpeg -c conda-forge

# 2. å®‰è£…LeRobot
git clone https://github.com/huggingface/lerobot.git
cd lerobot
pip install -e ".[smolvla]"

# 3. è½¬æ¢æ•°æ®é›†
python examples/port_datasets/port_aloha_hdf5.py \
    --raw-dir ./data/raw/aloha_recordings \
    --instruction-dir ./data/instructions \
    --repo-id myusername/aloha-pick-place \
    --output-dir ./data/lerobot/aloha-pick-place

# 4. éªŒè¯æ•°æ®é›†
lerobot-dataset-viz \
    --repo-id myusername/aloha-pick-place \
    --root ./data/lerobot \
    --mode local \
    --episode-index 0

# 5. è®­ç»ƒSmolVLA
lerobot-train \
    --policy-name smolvla \
    --repo-id myusername/aloha-pick-place \
    --root ./data/lerobot \
    --output-dir outputs/smolvla_aloha \
    --num-train-iters 10000 \
    --batch-size 8 \
    --eval-freq 1000 \
    --save-freq 1000 \
    --use-wandb \
    --wandb-project my-robotics-project

# 6. è¯„ä¼°æ¨¡å‹
lerobot-eval \
    --policy-path outputs/smolvla_aloha \
    --env aloha \
    --num-episodes 10
```

ç¥ä½ è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
