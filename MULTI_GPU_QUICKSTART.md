# Multi-GPU Training Quick Start

LeRobot ç°æœ‰çš„ `lerobot_train.py` å·²ç»å®Œæ•´æ”¯æŒå¤šå¡è®­ç»ƒï¼Œé€šè¿‡ [Accelerate](https://huggingface.co/docs/accelerate) å®ç°ã€‚

## ğŸš€ æœ€å¿«ä¸Šæ‰‹æ–¹å¼

```bash
# 1. å®‰è£… accelerateï¼ˆå¦‚æœè¿˜æ²¡å®‰è£…ï¼‰
pip install accelerate

# 2. é…ç½® accelerateï¼ˆä¸€æ¬¡æ€§è®¾ç½®ï¼‰
accelerate config default

# 3. å¯åŠ¨å¤šå¡è®­ç»ƒï¼ˆè‡ªåŠ¨æ£€æµ‹æ‰€æœ‰ GPUï¼‰
accelerate launch src/lerobot/scripts/lerobot_train.py \
    policy.pretrained_path=lerobot/smolvla_base \
    dataset.repo_id=your-username/your-dataset \
    batch_size=16
```

å°±æ˜¯è¿™ä¹ˆç®€å•ï¼

## ğŸ“Š å¸¸ç”¨å‘½ä»¤

### æŒ‡å®š GPU æ•°é‡

```bash
# ä½¿ç”¨ 4 å¼  GPU
accelerate launch --num_processes=4 \
    src/lerobot/scripts/lerobot_train.py [your args]

# ä½¿ç”¨ 2 å¼  GPU
accelerate launch --num_processes=2 \
    src/lerobot/scripts/lerobot_train.py [your args]
```

### æŒ‡å®šä½¿ç”¨å“ªäº› GPU

```bash
# åªä½¿ç”¨ GPU 0 å’Œ 1
CUDA_VISIBLE_DEVICES=0,1 accelerate launch --num_processes=2 \
    src/lerobot/scripts/lerobot_train.py [your args]

# ä½¿ç”¨ GPU 2,3,4,5
CUDA_VISIBLE_DEVICES=2,3,4,5 accelerate launch --num_processes=4 \
    src/lerobot/scripts/lerobot_train.py [your args]
```

### å¼€å¯æ··åˆç²¾åº¦ï¼ˆæ›´å¿«ï¼‰

```bash
# æ¨èï¼šBF16ï¼ˆé€‚ç”¨äº A100, RTX 3090 ç­‰ï¼‰
accelerate launch \
    --num_processes=4 \
    --mixed_precision=bf16 \
    --multi_gpu \
    src/lerobot/scripts/lerobot_train.py [your args]

# æˆ–ä½¿ç”¨ FP16ï¼ˆé€‚ç”¨äºè€æ˜¾å¡ï¼‰
accelerate launch \
    --num_processes=4 \
    --mixed_precision=fp16 \
    --multi_gpu \
    src/lerobot/scripts/lerobot_train.py [your args]
```

## ğŸ¯ è®­ç»ƒ SmolVLA ç¤ºä¾‹ï¼ˆ4 å¡ï¼‰

### æ–¹æ³• 1ï¼šä½¿ç”¨ç¤ºä¾‹è„šæœ¬ï¼ˆæœ€ç®€å•ï¼‰

```bash
# ä¿®æ”¹é…ç½®
vim examples/train_smolvla_multi_gpu.sh

# è¿è¡Œè®­ç»ƒ
bash examples/train_smolvla_multi_gpu.sh
```

### æ–¹æ³• 2ï¼šç›´æ¥ä½¿ç”¨ Accelerate

```bash
# åŸºç¡€å¤šå¡è®­ç»ƒ
accelerate launch --num_processes=4 \
    src/lerobot/scripts/lerobot_train.py \
    policy.pretrained_path=lerobot/smolvla_base \
    dataset.repo_id=christianwang-sjtu/so100-red-dustbin \
    batch_size=12 \
    output_dir=outputs/smolvla_4gpu

# åŠ ä¸Šæ··åˆç²¾åº¦åŠ é€Ÿ
accelerate launch \
    --num_processes=4 \
    --mixed_precision=bf16 \
    --multi_gpu \
    src/lerobot/scripts/lerobot_train.py \
    policy.pretrained_path=lerobot/smolvla_base \
    dataset.repo_id=christianwang-sjtu/so100-red-dustbin \
    batch_size=12 \
    output_dir=outputs/smolvla_4gpu_bf16
```

## ğŸ’¡ é‡è¦é…ç½®è¯´æ˜

### Batch Size è°ƒæ•´

**æœ‰æ•ˆ batch size** = `batch_size` Ã— `GPU æ•°é‡`

```yaml
# ä¾‹å¦‚ï¼š4 å¡ï¼Œbatch_size=12
# æœ‰æ•ˆ batch size = 12 Ã— 4 = 48

# å¦‚æœä½ ä¹‹å‰å•å¡ç”¨ batch_size=48
# ç°åœ¨ 4 å¡åº”è¯¥ç”¨ batch_size=12ï¼ˆä¿æŒæœ‰æ•ˆ batch size ä¸€è‡´ï¼‰
batch_size: 12
```

### Learning Rate è°ƒæ•´

å½“æœ‰æ•ˆ batch size æ”¹å˜æ—¶ï¼Œé€šå¸¸éœ€è¦è°ƒæ•´å­¦ä¹ ç‡ï¼š

```yaml
# å•å¡ï¼šbatch_size=48, lr=1e-4
# 4 å¡ï¼šbatch_size=12, lr=1e-4ï¼ˆæœ‰æ•ˆ batch size ç›¸åŒï¼Œlr ä¸å˜ï¼‰

# å¦‚æœå¢å¤§æœ‰æ•ˆ batch sizeï¼š
# å•å¡ï¼šbatch_size=48,  lr=1e-4
# 4 å¡ï¼šbatch_size=48,  lr=2e-4ï¼ˆæœ‰æ•ˆ batch size = 192ï¼Œlr ç¿»å€ï¼‰
```

**ç»éªŒè§„åˆ™**ï¼šæœ‰æ•ˆ batch size ç¿»å€ï¼Œlr å¢åŠ  âˆš2 åˆ° 2 å€ã€‚

### Workers æ•°é‡

```yaml
# å‡è®¾ 4 å¡ï¼Œ32 æ ¸ CPU
num_workers: 8  # æ¯å¡ 8 ä¸ª workerï¼Œæ€»å…± 32 ä¸ª worker

# æ¨èèŒƒå›´ï¼šæ¯å¡ 4-8 ä¸ª worker
```

## ğŸ” ç›‘æ§è®­ç»ƒ

### æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µ

```bash
# å®æ—¶ç›‘æ§
watch -n 1 nvidia-smi

# æˆ–ä½¿ç”¨ gpustatï¼ˆæ›´å‹å¥½ï¼‰
pip install gpustat
gpustat -i 1
```

### æœŸæœ›çš„ GPU åˆ©ç”¨ç‡

- âœ… **è‰¯å¥½**ï¼šæ‰€æœ‰ GPU åˆ©ç”¨ç‡ 80-100%
- âš ï¸ **ä¸€èˆ¬**ï¼šåˆ©ç”¨ç‡ 50-80%ï¼ˆå¯èƒ½éœ€è¦å¢å¤§ batch_sizeï¼‰
- âŒ **ä¸ä½³**ï¼šåˆ©ç”¨ç‡ <50%ï¼ˆæ•°æ®åŠ è½½ç“¶é¢ˆæˆ– batch_size å¤ªå°ï¼‰

## ğŸ”§ å¸¸è§é—®é¢˜

### æ˜¾å­˜ä¸è¶³ï¼ˆOOMï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å‡å°æ¯å¡çš„ `batch_size`
2. å¼€å¯æ··åˆç²¾åº¦ `--mixed_precision=bf16`
3. å‡å°‘ `num_workers`

```yaml
batch_size: 8   # ä» 16 é™åˆ° 8
num_workers: 4  # ä» 8 é™åˆ° 4
```

### è®­ç»ƒé€Ÿåº¦æ…¢

**è¯Šæ–­**ï¼š
```bash
# æŸ¥çœ‹ GPU åˆ©ç”¨ç‡
nvidia-smi
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```yaml
# å¦‚æœæ˜¾å­˜å……è¶³ï¼Œå¢å¤§ batch_size
batch_size: 24  # ä» 12 å¢åŠ åˆ° 24

# å¢åŠ  workersï¼ˆå¦‚æœ CPU æ ¸å¿ƒå……è¶³ï¼‰
num_workers: 12  # ä» 8 å¢åŠ åˆ° 12
```

### GPU ä¹‹é—´è´Ÿè½½ä¸å‡

**æ£€æŸ¥**ï¼š
```bash
# ç›‘æ§å„ä¸ª GPU
nvidia-smi dmon -i 0,1,2,3
```

**åŸå› **ï¼šé€šå¸¸æ˜¯ç¡¬ä»¶å·®å¼‚æˆ–æ•°æ®åˆ†å¸ƒé—®é¢˜
**è§£å†³**ï¼šç¡®ä¿æ‰€æœ‰ GPU å‹å·ç›¸åŒ

## ğŸ“ˆ æ€§èƒ½å‚è€ƒ

åœ¨ NVIDIA A100 ä¸Šè®­ç»ƒ SmolVLA çš„åŠ é€Ÿæ¯”ï¼š

| GPU æ•°é‡ | æ¯å¡ Batch Size | åŠ é€Ÿæ¯” | æ•ˆç‡ |
|---------|----------------|--------|------|
| 1       | 32             | 1.0Ã—   | 100% |
| 2       | 32             | 1.9Ã—   | 95%  |
| 4       | 32             | 3.7Ã—   | 93%  |
| 8       | 32             | 5.4Ã—   | 68%  |

*æ³¨ï¼šæ•ˆç‡ = åŠ é€Ÿæ¯” / GPUæ•°é‡ï¼Œéšç€ GPU æ•°é‡å¢åŠ ï¼Œæ•ˆç‡ä¼šå› é€šä¿¡å¼€é”€è€Œé™ä½*

## âš ï¸ é‡è¦æç¤º

1. **æœ‰æ•ˆ Batch Size**ï¼šN å¡ Ã— batch_size = æœ‰æ•ˆ batch_size
2. **å­¦ä¹ ç‡è°ƒæ•´**ï¼šæ”¹å˜æœ‰æ•ˆ batch size æ—¶éœ€è¦è°ƒæ•´ lr
3. **éšæœºç§å­**ï¼šæ¯å¼  GPU ä½¿ç”¨ä¸åŒç§å­ï¼ˆseed + rankï¼‰ç¡®ä¿æ•°æ®ä¸é‡å¤
4. **Checkpoint ä¿å­˜**ï¼šåªæœ‰ä¸»è¿›ç¨‹ï¼ˆrank 0ï¼‰ä¿å­˜æ¨¡å‹
5. **WandB æ—¥å¿—**ï¼šåªæœ‰ä¸»è¿›ç¨‹ä¸Šä¼ æ—¥å¿—ï¼Œé¿å…é‡å¤

## ğŸ“– å®Œæ•´æ–‡æ¡£

è¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹ï¼š
- **ç¤ºä¾‹è„šæœ¬**: [`examples/MULTI_GPU_EXAMPLES.md`](examples/MULTI_GPU_EXAMPLES.md)
- **è¯¦ç»†æŒ‡å—**: [`docs/MULTI_GPU_TRAINING.md`](docs/MULTI_GPU_TRAINING.md)

## âœ… ç°æœ‰åŠŸèƒ½

`lerobot_train.py` å·²ç»å†…ç½®ï¼š

âœ… è‡ªåŠ¨æ£€æµ‹å¤š GPUï¼ˆé€šè¿‡ Accelerateï¼‰
âœ… æ¢¯åº¦è·¨ GPU åŒæ­¥
âœ… æ··åˆç²¾åº¦è®­ç»ƒ
âœ… åˆ†å¸ƒå¼æ•°æ®åŠ è½½
âœ… Checkpoint ä¿å­˜ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
âœ… WandB æ—¥å¿—ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
âœ… æŒ‡æ ‡è·¨è¿›ç¨‹èšåˆ
âœ… å¤šèŠ‚ç‚¹è®­ç»ƒæ”¯æŒ

**æ— éœ€ä¿®æ”¹ä»»ä½•ä»£ç ï¼Œç›´æ¥ä½¿ç”¨ Accelerate å¯åŠ¨å³å¯ï¼**

## ğŸ“ ä¸‹ä¸€æ­¥

1. æŸ¥çœ‹ç¤ºä¾‹è„šæœ¬ï¼š`examples/train_smolvla_multi_gpu.sh`
2. é˜…è¯»å®Œæ•´æŒ‡å—ï¼š`docs/MULTI_GPU_TRAINING.md`
3. å°è¯•ä¸åŒçš„ batch size å’Œå­¦ä¹ ç‡ç»„åˆ
4. ä½¿ç”¨æ··åˆç²¾åº¦åŠ é€Ÿè®­ç»ƒ
5. ç”¨ WandB ç›‘æ§è®­ç»ƒè¿‡ç¨‹

## å‚è€ƒèµ„æ–™

- [Accelerate æ–‡æ¡£](https://huggingface.co/docs/accelerate)
- [Accelerate å¿«é€Ÿå…¥é—¨](https://huggingface.co/docs/accelerate/quicktour)
- [å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ](https://huggingface.co/docs/accelerate/basic_tutorials/launch)
